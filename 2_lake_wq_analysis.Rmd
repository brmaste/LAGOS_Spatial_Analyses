---
title: "Lake Water Quality Analysis"
author: "Matthew Ross"
date: "9/17/2019"
output:
  html_document:
    toc: true
    toc_float: true
editor_options: 
  chunk_output_type: console
---



```{r setup, include=FALSE}
library(tidyverse) # Tidy packages
library(sf) #Spatial package that can read and create shapefiles 
library(mapview) #Interactive maps
library(LAGOSNE) #Lots and lots of clean lake data
library(USAboundaries) #USA states and counties
library(lubridate) #For dealing with date and time
library(ggthemes)
library(kableExtra)
```


# LAGOS Analysis


## Loading in data


### First download and then specifically grab the locus (or site lat longs)
```{r data-read, warning=F,message=F}
#Lagos download script
#lagosne_get(dest_folder = LAGOSNE:::lagos_path(),overwrite=T)

#Load in lagos
lagos <- lagosne_load()


#Grab the lake centroid info
lake_centers <- lagos$locus

# Make an sf object 
spatial_lakes <- st_as_sf(lake_centers,coords=c('nhd_long','nhd_lat'),
                          crs=4326)

#Grab the water quality data
nutr <- lagos$epi_nutr

#Look at column names
names(nutr)
```

### Subset columns nutr to only keep key info that we want


```{r}
clarity_only <- nutr %>%
  select(lagoslakeid,sampledate,chla,doc,secchi) %>%
  mutate(sampledate = as.character(sampledate) %>% ymd(.))

```


### Keep sites with at least 200 observations 

```{r}

#Look at the number of rows of dataset
#nrow(clarity_only)

chla_secchi <- clarity_only %>%
  filter(!is.na(chla), 
         !is.na(secchi))

# How many observatiosn did we lose?
# nrow(clarity_only) - nrow(chla_secchi)


# Keep only the lakes with at least 200 observations of secchi and chla
chla_secchi_200 <- chla_secchi %>%
  group_by(lagoslakeid) %>%
  mutate(count = n()) %>%
  filter(count > 200)


```


### Join water quality data to spatial data

```{r}
spatial_200 <- inner_join(spatial_lakes,chla_secchi_200 %>%
                            distinct(lagoslakeid,.keep_all=T),
                          by='lagoslakeid')


```

### Mean Chl_a map

```{r}
### Take the mean chl_a and secchi by lake

mean_values_200 <- chla_secchi_200 %>%
  # Take summary by lake id
  group_by(lagoslakeid) %>%
  # take mean chl_a per lake id
  summarize(mean_chl = mean(chla,na.rm=T),
            mean_secchi=mean(secchi,na.rm=T)) %>%
  #Get rid of NAs
  filter(!is.na(mean_chl),
         !is.na(mean_secchi)) %>%
  # Take the log base 10 of the mean_chl
  mutate(log10_mean_chl = log10(mean_chl))

#Join datasets
mean_spatial <- inner_join(spatial_lakes,mean_values_200,
                          by='lagoslakeid') 

#Make a map
mapview(mean_spatial,zcol='log10_mean_chl')
```


# Class work

## 1) What is the correlation between Secchi Disk Depth and Chlorophyll a for
sites with at least 200 observations?

- Here, I just want a plot of chla vs secchi for all sites 

```{r, warning=F,message=F}

ggplot(chla_secchi_200,aes(x=chla,y=secchi)) + 
  geom_point(size = 0.5, color = 'dark green') +
  geom_smooth(method = lm) +
  theme_base() + 
  scale_x_log10() +
  xlab("Chlorophl A (mg/L)") +
  ylab("Secchi Depth (m)")

```


## Why might this be the case? 

*As chlorophyll A increases, depths at which a Secchi disk can be observed decrease. This is seen in the figure where the fewer the amounts of chlorophyll A increases the depths of the Secchi disk observations.*

## 2) What states have the most data? 

*Since this assignment is the "Lake Water Quality Analysis," I'm assuming this question means different water quality parameters from the "nutr" category.*

*According to the table below, Minnesota has the highest number of water quality observations (358,137), followed by Wisconsin (145,910), with Michigan having the third highest (100,683).*

### 2a) First you will need to make a lagos spatial dataset that has the total 
number of counts per site.

```{r, warning=F,message=F}

# df with a count per WQ observation:
nutr_count <- nutr %>%
  group_by(lagoslakeid) %>%
  summarise(count = n())

#Joining the nutr_count df to the spatial df:
join_spatial_nutr <- inner_join(spatial_lakes,nutr_count,
                          by='lagoslakeid')

```


### 2b) Second, you will need to join this point dataset to the us_boundaries 
data. 

```{r, warning=F,message=F}
# Using the us-states function to create a df:
states <- us_states()

# joining the two dfs
state_nutr_counts <- st_join(states, join_spatial_nutr)
#head(state_nutr_counts)
```


### 2c) Then you will want to group by state and sum all the observations in that
state and arrange that data from most to least toatl observations per state. 

```{r, warning=F,message=F}
# Grouping by state and summing observations by the states:
sum_nutr_state <- state_nutr_counts %>% 
  group_by(state_name) %>% 
  summarize(obs = sum(count)) %>% 
  arrange(-obs)

# table
head(sum_nutr_state) %>% 
  kable(.,'html') %>%
  kable_styling() %>%
  scroll_box(width='800px',height='300px')

```

## 3) Is there a spatial pattern in Secchi disk depth for lakes with at least 200 
observations?

*There is not an obvious spatial pattern for Secchi disk depth by looking at depths spatially, other than lakes with at least 200 observations appear to be close to large population centers which likely rely on the lakes and reservoirs for water (excluding the lakes in Northern Wisconsin).*

```{r, warning=F,message=F}
#This only uses the spatial df Matt created earlier:
mapview(spatial_200,zcol = 'secchi',  layer.name = "Secchi Depth (m)")

```


